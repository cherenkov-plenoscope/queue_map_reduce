import numpy
import pickle
import os
import stat
import subprocess as sp
import qstat
import time


def submitt_qsub(
    script_exe_path,
    script_path,
    arguments,
    job_name,
    queue_name=None,
    stdout_path=None,
    stderr_path=None,
):
    o_path = stdout_path if stdout_path is not None else '/dev/null'
    e_path = stderr_path if stderr_path is not None else '/dev/null'

    for p in [o_path, e_path]:
        if p == '/dev/null':
            continue
        if os.path.exists(p):
            os.remove(p)
        else:
            os.makedirs(os.path.dirname(p), exist_ok=True)

    cmd = ['qsub']
    if queue_name:
        cmd += ['-q', queue_name]
    cmd += ['-o', o_path,]
    cmd += ['-e', e_path,]
    cmd += ['-N', job_name,]
    cmd += ['-V',] # export enivronment variables on worker node
    cmd += ['-S', script_exe_path,]
    cmd += [script_path]
    for argument in arguments:
        cmd += [argument]

    try:
        sp.check_output(cmd, stderr=sp.STDOUT)
    except sp.CalledProcessError as e:
        print('returncode', e.returncode)
        print('output', e.output)
        raise

def current_python_path():
    bin_stdout = sp.check_output(['which', 'python'])
    stdout = bin_stdout.decode('ascii')
    #remove newline
    stdout = stdout.strip()
    stdout = os.path.abspath(stdout)
    assert(os.path.exists(stdout))
    return stdout

def job_path(tmp_dir, idx):
    return os.path.abspath(
        os.path.join(tmp_dir, "{:09d}.pkl".format(idx)))

def job_name_timestamp():
    return time.strftime("%Y%m%d%H%M%S", time.gmtime())

def job_name(time_stamp, idx):
    return "cp.{:s}.{:09d}".format(time_stamp, idx)

def map(function, jobs, python_path=None):
    if python_path is None:
        python_path = current_python_path()

    time_stamp = job_name_timestamp()
    tmp_dir = '.'+time_stamp
    os.makedirs(tmp_dir, exist_ok=True)
    for idx, job in enumerate(jobs):
        with open(job_path(tmp_dir, idx), 'wb') as f:
            f.write(pickle.dumps(job))
    out = '# generated by sge.py\n'
    out += 'from {:s} import {:s}\n'.format(function.__module__, function.__name__)
    out += 'import pickle\n'
    out += 'import sys\n'
    out += '\n'
    out += 'assert(len(sys.argv) == 2)\n'
    out += 'with open(sys.argv[1], "rb") as f:\n'
    out += '    job = pickle.loads(f.read())\n'
    out += '\n'
    out += '{:s}(job)\n'.format(function.__name__)
    out += '\n'
    script_path = os.path.join(tmp_dir, 'worker_node_script.py')
    with open(script_path, 'wt') as f:
        f.write(out)
    st = os.stat(script_path)
    os.chmod(script_path, st.st_mode | stat.S_IEXEC)

    time_stamp = job_name_timestamp()
    job_names = []
    for idx in range(len(jobs)):
        job_names.append(
            job_name(
                time_stamp=time_stamp,
                idx=idx))
        submitt_qsub(
            script_exe_path=python_path,
            script_path=script_path,
            arguments=[job_path(tmp_dir, idx)],
            job_name=job_names[-1],
            queue_name=None,
            stdout_path=job_path(tmp_dir, idx)+'.o',
            stderr_path=job_path(tmp_dir, idx)+'.e',
        )

    job_names_set = set(job_names)
    user_name = os.environ['USER']
    still_running = True
    while still_running:
        running, pending = qstat.qstat()
        still_running = False
        num_running = 0
        for j in running + pending:
            if j['JB_name'] in job_names_set:
                still_running = True
                num_running += 1
        print("{:d} jobs are still running".format(num_running))
        time.sleep(5)

    return True
